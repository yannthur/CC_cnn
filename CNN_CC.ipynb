{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7dc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import tensorflow as tf \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import splitfolders\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6461ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 20212 files [00:14, 1403.24 files/s]\n"
     ]
    }
   ],
   "source": [
    "#division des jeu de données\n",
    "splitfolders.ratio(\"Datasets\", output=\"dataset\", seed=42, ratio=(.7,.2,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa23f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation d'image \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.1, zoom_range = 0.1, horizontal_flip = True, rotation_range=15)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce334224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14142 images belonging to 10 classes.\n",
      "Found 2032 images belonging to 10 classes.\n",
      "Found 4038 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"dataset/train\",target_size=(64,64),batch_size=32, class_mode=\"categorical\")\n",
    "testing_set = test_datagen.flow_from_directory(\"dataset/test\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")\n",
    "validation_set = val_datagen = val_datagen.flow_from_directory(\"dataset/val\",target_size=(64,64),batch_size=32,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5839d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35 Complete [00h 04m 47s]\n",
      "val_accuracy: 0.26279526948928833\n",
      "\n",
      "Best val_accuracy So Far: 0.711614191532135\n",
      "Total elapsed time: 09h 09m 47s\n",
      "\n",
      "Search: Running Trial #36\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "32                |96                |conv_1_filter\n",
      "3                 |3                 |conv_1_kernel\n",
      "32                |48                |conv_2_filter\n",
      "5                 |5                 |conv_2_kernel\n",
      "3                 |3                 |pool_1_size\n",
      "0.2               |0.3               |dropout_rate\n",
      "48                |48                |conv_3_filter\n",
      "5                 |5                 |conv_3_kernel\n",
      "96                |64                |dense_1_units\n",
      "0.0001            |0.001             |learning_rate\n",
      "5                 |25                |tuner/epochs\n",
      "0                 |5                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "0                 |2                 |tuner/round\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m339/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - accuracy: 0.3133 - loss: 2.0216"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt # Nouvelle façon d'importer\n",
    "import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 1ère couche Conv\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(64, 64, 3)\n",
    "    ))\n",
    "    \n",
    "    # 2ème couche Conv\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    \n",
    "    # Pooling : Ajout de 2 dans les choix, car 3 ou 5 peut être trop grand pour 64x64\n",
    "    model.add(keras.layers.MaxPool2D(\n",
    "        pool_size=hp.Choice('pool_1_size', values=[2, 3])\n",
    "    ))\n",
    "    \n",
    "    # Dropout variable pour trouver le meilleur taux\n",
    "    model.add(keras.layers.Dropout(hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    \n",
    "    # 3ème couche Conv\n",
    "    model.add(keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_3_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    \n",
    "    # Couche de sortie (4 classes)\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=25,          \n",
    "    factor=5,\n",
    "    directory='output_new',\n",
    "    project_name='classification_Hyperband'\n",
    ")\n",
    "\n",
    "\n",
    "# Callback pour arrêter l'entraînement si un modèle ne s'améliore pas\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(training_set,epochs = 5, callbacks=[EarlyStopping(monitor='val_loss', mode='min',patience=10)], validation_data=(testing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf30b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e821b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81455fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ANN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
